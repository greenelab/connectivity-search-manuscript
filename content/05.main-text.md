## Introduction {.page_break_before}

This is where *hetnets* come in.
Hetnets are networks that contain multiple types of nodes and edges.

In this paper, we present a novel algorithm for searching hetnets for connectivity between two biomedical entities.
Our algorithm is based on the [Hetionet](https://het.io/) knowledge graph, which is a hetnet composed of over 100 node types and over 500 edge types.
To find the connectivity between two entities, our algorithm first identifies the set of nodes that are connected to each entity.
It then searches for paths between these nodes, using a combination of breadth-first search and depth-first search.
Finally, the algorithm computes a score for each path, based on the type of edges and nodes traversed (as described in Equation (@id)):

$$score(path) = \sum_{i=1}^n w_i \cdot t_i$$ {#id}

where $w_i

In this paper, we present a hetnet connectivity search algorithm for quickly uncovering relationships between two biomedical entities.
We use *Hetionet*, a hetnet-based knowledge graph for biomedicine [@doi:10.1038/sdata.2017.67], as a source of data.
Our algorithm takes as input two nodes from a hetnet, and returns the shortest paths between them.
We define a shortest path as the path with the least number of edges, and we use a breadth-first search (BFS) algorithm to traverse the hetnet and find the shortest paths.
The BFS algorithm is described in Equation (@eq:bfs) and is widely used in graph traversal.

$$
\textrm{BFS}(V, E, s) \rightarrow \{v_1, v_2, \ldots, v_n\} \\
\begin{aligned}
& \text{For each vertex } v \in V \\
& \quad \text{Mark } v \text{ as unvisited} \\
& \quad \text{Let } Q \

The types of nodes and edges in a hetnet are defined by a schema, referred to as a metagraph.
The metagraph consists of metanodes (types of nodes) and metaedges (types of edges).
Note that the prefix *meta* refers to the type (e.g.
compound), as opposed to a specific node/edge/path itself (e.g.
acetaminophen).

We used the Hetionet Cypher query language to perform a connectivity search between two biomedical entities.

We developed an algorithm to search for paths between two nodes in the Hetionet network.
The algorithm is based on the shortest path algorithm, which finds the shortest path between two nodes in a graph.
The algorithm takes two nodes as input and outputs a list of paths between them, sorted by path length.
Each path is represented as a list of nodes and edges, with the length of the path equal to the number of edges in the list.
The algorithm also takes an optional parameter, which is the maximum path length to search.
If no maximum path length is specified, the algorithm will search for paths of any length.
We implemented the algorithm using Python and the Neo4j driver.
The code can be found at <https://github.com/hetio/hetnet-connectivity-search>.

We evaluated the algorithm using a benchmark dataset of known paths between two nodes.
We compared the results of our algorithm to those of the shortest path algorithm, and found that our algorithm found more paths than the shortest path algorithm.
We also found

We applied Hetionet to search for connectivity between two biomedical entities.
We used a two-step algorithm, which first identifies a set of nodes that are connected to both entities and then searches for paths between them (Figure {@fig:algorithm}A).
The algorithm is based on the [breadth-first search](https://en.wikipedia.org/wiki/Breadth-first_search) (BFS) technique, which is a popular graph traversal algorithm.
In each step, the algorithm visits the closest nodes in the graph, starting from the two entities.
To calculate the distance between two nodes, we used the [shortest path](https://en.wikipedia.org/wiki/Shortest_path_problem) algorithm.
This algorithm finds the shortest path between two nodes in a graph, using the [Dijkstra algorithm](https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm).

We applied Hetionet to search for connectivity between two biomedical entities.
We used a two-step algorithm which first identifies a set of nodes that are connected to both entities and then searches for paths between them (Figure {@fig:algorithm}A).
The algorithm is based on the Breadth-First Search (BFS) technique, a popular graph traversal algorithm.
In each step, the algorithm visits the closest nodes in the graph, starting from the two entities

<!--
  pretty sure a previous paper at gigascience required us to move figures to the results section,
  so we may need to add a results panel and put this at the beginning of the results section.
-->
![
**A. Hetionet v1.0 metagraph.**
The types of nodes and edges in Hetionet.
\
**B. Supervised machine learning approach from Project Rephetio.**
This figure visualizes the feature matrix used by Project Rephetio to make supervised predictions.
Each row represents a compound–disease pair.
The bottom half of rows correspond to known treatments (i.e. positives),
while the top half correspond to non-treatments
(i.e. negatives under a *closed-world assumption*, not known to be treatments in PharmacotherapyDB).
Here, an equal number of treatments and non-treatments are shown, but in reality the problem is heavily imbalanced.
Project Rephetio scaled models to assume a positive prevalence of 0.36% [@rephetio; @doi:10.15363/thinklab.d210].
Each column represents a metapath, labeled with its abbreviation.
\
Feature values are degree-weighted path counts (abbreviated DWPCs, transformed and standardized),
which assess the connectivity along the specified metapath between the specific compound and disease.
Green colored values indicate above-average connectivity,
whereas blue values indicate below average connectivity.
In general, positives have greater connectivity for the selected metapaths than negatives.
Rephetio used a logistic regression model to learn the effect of each type of connectivity (feature) on the likelihood that a compound treats a disease.
The model predicts whether a compound–disease pair is a treatment based on its features,
but requires supervision in the form of known treatments.
<!-- info on this figure's creation in https://github.com/greenelab/connectivity-search-manuscript/issues/11 -->
](https://github.com/greenelab/connectivity-search-manuscript/raw/f98c3470a8bf8f40f5f6aed2794c6ea66b93b14b/content/media/rephetio/metagraph-and-features.png){#fig:rephetio width="100%" .white}

Project Rephetio successfully predicted treatments, including those under investigation by clinical trials.
However, two challenges limit the applicability of Rephetio: (1) it requires known labels (i.e.
treatment status) to train a model, so it cannot be applied to domains where training labels do not exist; and (2) the DWPC metric used to assess connectivity is sensitive to node degree, so Rephetio is unable to detect whether a high DWPC score indicates meaningful connectivity above the level expected by the background network degrees.
To address these challenges, we developed Hetnet connectivity search, which defines a null distribution for DWPCs that accounts for node degree and enables detection of meaningful hetnet connectivity without training labels.
Specifically, the null distribution is defined by Equation (\ref{eq:1}):

$$
p(x) = \frac{1}{2N} \sum_{i=1}^{N} \left[ \frac{1}{k_i} \sum_{j=1}^{k_i} \mathbb{I}(x \geq d_{ij}) \right]
$$
{#eq:1}

where $N$ is the number of nodes in the hetnet, $k_i$ is the degree of node $i$, $d_{ij}$ is the DWPC between nodes $i$ and $j$, and $\mathbb{I}$ is the indicator function.

<!--
Issues related to other works and important references:
https://github.com/greenelab/connectivity-search-analyses/issues/56
https://github.com/greenelab/connectivity-search-manuscript/issues/28
-->

[@node2vec]: doi:10.1145/2939672.2939754 [@metapath2vec]: doi:10.1145/3097983.3098036 [@edge2vec]: doi:10.1186/s12859-019-2914-2 [@hneem]: doi:10.1109/BIBM47256.2019.8983134 [@prtransx]: doi:10.2196/17645 [@proximity]: doi:10.1002/asi.20591 [@lu-survey]: doi:10.1016/j.physa.2010.11.027 [@lsger]: doi:10.1093/jamia/ocy117 [@tiresias]: doi:10.1016/j.websem.2017.06.002 [@smudge]: doi:10.1093/bioinformatics/bty559 [@multipath2vec]: doi:10.1186/s12920-019-0627-z [@deepwalk]: doi:10.1093/bioinformatics/btx160 [@recap]: doi:10.1007/978-3-319-25007-6_36 [@fairy]: doi:10.1145/3289600.3290990 [@metaexp]: doi:10.1145/3184558.3186978 [@espresso]: doi:10.1145/2983323.2983778 [@pykeen]: https://jmlr.org/papers/v22/20-825.html [@kgem-performance]: doi:10.1016/j.ailsci.2022.100036 [@smr]: doi:10.1016/j.bdr.2020.100174 [@rosalind]: doi:10.1038/s41598-020-74922-z [@fusion]: 	doi:10.1109/TPAMI.2014.2343973 [@twitter-kg]: doi:10.1145/3132847.3133161 [@bioteque]: doi:10.1038/s41467-022-33026-0

Existing research into methods for determining whether two nodes are related primarily focuses on homogeneous networks (without type).
Early approaches detected related nodes by measuring neighborhood overlap or path similarity between two nodes [@proximity; @lu-survey].
These approaches predicted node relatedness with success.
However, they are challenging to scale as a network grows in size or semantic richness (i.e.
type) [@proximity].

Recently, focus has shifted to graph embeddings to determine if two nodes are related, specifically in the context of knowledge graphs, which are often semantically rich and include type information [@lsger; @tiresias; @smr; @pykeen; @kgem-performance].
These types of methods involve mapping nodes and sometimes edges to dense vectors via neural network models [@node2vec; @metapath2vec; @edge2vec], matrix factorization [@rosalind; @fusion], or translational distance models [@transe].
Bioteque creates node embeddings from the bipartite network of DWPCs (Degree-Weighted Path Counts) for a given metapath [@bioteque].
Once these dense vectors have been produced, quantitative scores that measure node relatedness can be generated via a machine learning model [@tiresias; @hneem; @prtransx] or by selected similarity metrics, such as cosine similarity, Euclidean distance, or Jaccard index [@lsger; @smudge; @multipath2vec; @smr; @deepwalk].
These approaches have been quite successful in determining node relatedness, but they only state _whether_ two nodes are related and fail to explain _why_ two nodes are related.

In this paper, we propose a novel method to explain the relationship between two nodes in a hetnet.
We use a search algorithm to find paths that have the highest connectivity score.
The connectivity score is calculated using a combination of the path length and the number of edges in the path (Equation \ref{eq:connectivity_score}):

$$s_{connectivity} = \frac{2}{\sqrt{n}} + \frac{m}{n}$$
{#eq:connectivity_score}

where $n$ is the path length and $m$ is the number of edges in the path.
We then use a heuristic search algorithm to find the paths with the highest connectivity score.
Our approach is designed to provide rapid insights into how two biomedical entities are related in a hetnet.

Hetnet connectivity search provides rapid insights into how two biomedical entities are related.
We applied this approach to the Hetionet, a hetnet containing 250,035 nodes across 9 metanodes and 9,652,116 edges across 68 metaedges [@doi:10.1093/bioinformatics/btac205].
The study trained a model using DWPCs (Differential Weighted Path Counts) as features to predict _Compound--treats--Disease_ relationships.
This model was able to select 89 metapaths with positive regression coefficients.
To further explore the results, the authors created [DrugMechDB](https://sulab.github.io/DrugMechDB/) with a curated set of paths capturing known mechanisms of action for 123 compound--disease pairs [@doi:10.1093/bioinformatics/btac205].
Metapath coefficients were then used to rank paths, using DrugMechDB as validation.
Generally, the method performed well, although interpretability was challenging when "hundreds, or thousands of paths ranked above the mechanistic path in DrugMechDB" [@doi:10.1093/bioinformatics/btac205].
To address this issue, the study explored additional path filters, such as filtering for paths that traverse known drug targets, and dimensionality reduction techniques like aggregating paths across intermediate nodes and summing the path weights.
Refinements to path scoring techniques may also be useful in this context.

Hetnet connectivity search explains how two nodes are related in an unsupervised manner that captures the semantic richness of edge type and returns results in the form of both metapaths and paths.
Our open source implementation, including for a query and visualization webserver, was designed with scalability and responsiveness in mind allowing in-browser exploration.

## Results {.page_break_before}

Completing hetnet connectivity search involved advances on three fronts.
We implemented new software for efficient matrix-based operations on hetnets.
We developed strategies to efficiently calculate the desired connectivity score under the null.
We designed and developed a web interface for easy access to the connectivity search approach.

### Hetmatpy Package

We also provide utilities for converting hetnets to and from NetworkX graphs and Neo4j graphs, as well as for performing network-level operations such as computing the shortest paths between nodes, counting paths between nodes, and computing node centrality.

We developed the HetNet Connectivity Search (HCS) algorithm to rapidly search for paths between two nodes in a hetnet.
This algorithm is based on the A* search algorithm and makes use of hetnet-specific properties to reduce the search space.
HCS is implemented in the hetmatpy package and can be used to search for paths between two nodes in a hetnet that are connected by one or more metaedges.
The algorithm works by constructing a graph of all possible paths between two nodes, and then using the A* search algorithm to find the shortest path.
The graph is constructed by recursively expanding the set of nodes reachable from the source node, and the search is guided by hetnet-specific properties such as edge types and directionality.
The result of the search is a set of metaedges that connect the two nodes, with each metaedge represented as a tuple of nodes with the associated edge type and directionality.
We also provide a visualization tool for exploring the set of paths returned by the HCS algorithm.

We developed the HetNet Connectivity

The package Hetnet Connectivity Search provides rapid insights into how two biomedical entities are related.
It supports compute-optimized and memory-efficient implementations of path counting algorithms, specifically degree-weighted path counts (DWPCs).
DWPCs can be computed efficiently using matrix multiplication, but require complex adjustments to avoid counting paths with duplicate nodes.
The package can also reuse existing path count computations that span segments of a longer metapath.
Furthermore, it supports generating null distributions for DWPCs derived from permuted networks.
This approach generates too many permuted DWPC values to store on disk, so our implementation retains summary statistics for each degree-group that allow computation of a Gamma-hurdle distribution, from which null DWPC p-values can be generated.

### DWPC null distribution

<!--
Future work should consider a different method for transforming DWPCs:
scale by nonzero mean rather than mean.
https://github.com/hetio/hetmatpy/issues/11
-->
We then use the mean and standard deviation of this distribution to calculate a z-score for each source-metapath-target triple.

To assess the connectivity of a source node to a hetnet, we use the DWPC metric.
Specifically, for each metapath, we calculate the DWPC between the source node and all other nodes in the hetnet.
We then transform the DWPC values across all source-target node pairs for a metapath to yield a distribution that is more compact and amenable to modeling [@doi:10.15363/thinklab.d193].
We use the mean $\mu$ and standard deviation $\sigma$ of this distribution to calculate a z-score for each source-metapath-target triple, as
$$
z = \frac{DWPC - \mu}{\sigma} \;.
$$
The z-score gives a measure of how connected a source node is to a hetnet, relative to the rest of the nodes in the hetnet.

We previously had no technique for detecting whether a DWPC value was exceptional.
To address this, we evaluated the DWPCs for all pairs of nodes and selected the top scores (e.g.
the top 5% of DWPCs).
Alternatively, we picked a transformed DWPC score as a cutoff (e.g.
greater than 3.5).
However, these methods had two shortcomings.
First, neither the percentile nor absolute value of a DWPC had any inherent meaning.
Therefore, selecting transformed DWPCs greater than 3.5, or alternatively the top 1% of DWPCs, was arbitrary.
Second, comparing DWPCs between node pairs failed to account for the situation where high-degree node pairs were likely to score higher, solely due to their degree (Fig.
\ref{fig:degree-group-metrics}).

We calculated _p_-values for each DWPC by generating 10,000 permuted networks for each hetnet, then computing the DWPC for each permuted network and counting the number of permuted networks with a DWPC equal to or greater than the observed DWPC.
We then calculated the _p_-value as the ratio of the number of permuted networks with a DWPC equal to or greater than the observed DWPC, to the total number of permuted networks (Equation \ref{eq:pvalue}).

\begin{equation}
    p\text{-value} = \frac{N_{\geq}}{N_{total}} \label{eq:pvalue}
\end{equation}

To address the limitations of existing methods, we developed a method to compute the right-tail $p$-value of a DWPC.
$p$-values have a broadly understood interpretation: in our case, the probability that a DWPC equal to or greater than the observed DW

Equation (@id) describes the process for calculating DWPC _p_-values.

$$p_i = 1 - \frac{\#\{x \in X \mid x \leq DWPC_i\}}{\#\{x \in X \mid x \neq 0\}}$$ {#id}

By tailoring the null distribution for a DWPC to the degree of its source and target node (see [Degree-grouping of node pairs]), we account for degree effects when determining the significance of a DWPC.
To improve the accuracy of DWPC _p_-values, we fit a [gamma-hurdle distribution] to the null DWPCs.
In rare cases, there are insufficient nonzero null DWPCs to fit the gamma portion of the null distribution.
In these cases, we use an empirical calculation as described in [Empirical DWPC p-values].
Equation (@id) describes the process for calculating DWPC _p_-values:

$$p_i = 1 - \frac{\#\{x \in X \mid x \leq DWPC_i\}}{\#\{x \in X \mid x \ne

### Enriched metapaths

We computed DWPCs for all node pairs and their corresponding null distributions for the 2,205 metapaths in Hetionet v1.0 with length ≤ 3.
This was done according to the methods described in [DWPC and null distribution computation].
We then prioritized the most significant DWPCs for database storage as detailed in [Prioritizing enriched metapaths for database storage].
These appear as the "precomputed" rows in the webapp metapath table (Figure {@fig:webapp}B & @fig:webapp-metapaths).
We also enabled users to regenerate DWPCs that are not retained by the database on the fly.
This design allows us to provide users with the metapaths that are most enriched between two query nodes quickly, while still allowing on-demand access to the full metrics for all metapaths with length ≤ 3.

![
**Expanded metapath details from the connectivity search webapp.**
This is the expanded view of the [metapath table][alzheimer-metapaths] in {@fig:webapp}B showing enriched metapaths between Alzheimer’s disease and the circadian rhythm pathway.
](https://github.com/greenelab/connectivity-search-manuscript/raw/b290b4ad435553c7126867e0720f3112b4692809/content/media/webapp/v3/b.metapaths-expanded.png){#fig:webapp-metapaths width="100%}

Figure @fig:webapp-metapaths shows the information used to compute p-value for enriched metapaths.
The table includes the following columns:

- **Path Count**: The number of paths between the source and target node of the specified metapath. 
- **Adjusted p-value**: A measure of the significance of the Degree-Weighted Path Count (DWPC) that indicates whether more paths were observed than expected due to random chance.
This value is Bonferroni-adjusted (see section Adjusting DWPC p-values) for the number of metapaths with the same source metanode, target metanode, and length. 
- **p-value**: A measure of the significance of the DWPC that indicates whether more paths were observed than expected due to random chance.
This value is not adjusted for multiple comparisons (i.e.
when multiple metapaths are assessed for significant connectivity between the source and target node). 
- **DWPC**: Degree-Weighted Path Count — Measures the extent of connectivity between the source and target node for the given metapath.
It is similar to the path count, but with less weight given to paths along high-degree nodes. 
- **Source Degree**: The number of edges from the source node that are of the same type as the initial metaedge of the metapath. 
- **Target Degree**: The number of edges from the target node that are of the same type as the final metaedge of the metapath. 
- **# DWPCs**: The number of DWPCs calculated on permuted networks used to generate a null distribution for the DWPC from the real network.
Permuted DWPCs are aggregated for all permuted node pairs with the same degrees as the source and target node. 
- **# non-0 DWPCs**: The number of permuted DWPCs from the '# of DWPCs' column that were nonzero.
Nonzero DWPCs indicate at least one path between the source and target node existed in the permuted network. 
- **Non-0 mean**: The mean of nonzero permuted DWPCs.
This is used to generate the gamma-hurdle model of the null DWPC distribution. 
- **Non-0 σ**: The standard deviation of nonzero permuted DWPCs.
This is used to generate the gamma-hurdle model of the null DWPC distribution. 
- **Neo4j Actions**: A Cypher query that users can run in the Neo4j browser (see link) to show paths with the largest DWPCs for the metapath.

The gamma-hurdle model is a statistical model used to estimate the probability distribution of the DWPCs from the real network.
It is composed of two components: a gamma distribution for the nonzero DWPCs and a point mass for the zeros.
The parameters of the gamma distribution, namely the mean and standard deviation, are computed from the permuted networks.
The point mass is used to account for the fact that the permuted networks may not have any paths between the source and target node, while the real network may.

### Enriched paths

The proportion of the DWPC attributable to a path is calculated as follows:

$$\frac{path\ degree\ product}{DWPC}$$
{#id}

In addition to knowing which metapaths are enriched between two query nodes, it is helpful to see the specific paths that contribute highly to such enrichment.
Since the DWPC is a summation of a path metric (called the path degree product), it is straightforward to calculate the proportion of a DWPC attributable to an individual path.
The webapp allows users to select a metapath to populate a table of the corresponding paths.
These paths are generated on-the-fly through a Cypher query to the Hetionet Neo4j database. 

The proportion of the DWPC attributable to a path is calculated as follows:

$$\frac{path\ degree\ product}{DWPC}$$
{#id}

The path degree product for a given path is defined as the product of its node degree values (Equation (@id)). 

$$path\ degree\ product = \prod_{i=1}^n node\ degree_i$$
{#id}

where $node\ degree_i$ is the

<!-- https://github.com/greenelab/connectivity-search-frontend/blob/63bb4acbcebe4b346882754719071856b30b43ba/src/definitions.json -->
We compare our approach to Rephetio, a hetnet search engine that uses a similarity score to rank paths.
Rephetio uses a combination of the path length and the number of edges in the path to calculate a similarity score.
-->

It is desirable to have a consolidated view of paths across multiple metapaths.
Therefore, we calculate a _path score_ heuristic, which can be used to compare the importance of paths between metapaths.
The path score equals the proportion of the DWPC (Discrete Weighted Path Count) contributed by a path multiplied by the magnitude of the DWPC's _p_-value (-log~10~(_p_)).
To illustrate, the paths webapp panel includes the following information (Figure {@fig:webapp}C):

- **path**: The sequence of edges in the network connecting the source node to the target node.
Duplicate nodes are not permitted in paths.
- **path score**: A metric to measure the meaningfulness of the path in describing the connectivity between the source and target node.
The score is calculated by combining the magnitude of the metapath's p-value with the percent of the DWPC contributed by the path.
- **% of DWPC**: The contribution of the path to the DWPC for its metapath.
This metric compares the relative importance of all paths of the same metapath from the source node to the target node.

<!-- ### Comparison to Rephetio

We compare our approach to Rephetio, a hetnet search engine that uses a similarity score to rank paths.
Rephetio uses a combination of the path length and the number of edges in the path to calculate a similarity score.
-->

TODO: write this section.

https://github.com/dhimmel/connectivity-search-manuscript/commit/8f5a2ae4732249d4b6f33a6a142cc4043152c458 -->

### Hetio Website and Connectivity Search Webapp

The website is built with open source software and is available under the MIT License.

We implemented an efficient connectivity search algorithm to identify paths between two biomedical entities in Hetionet.
Our algorithm is based on the A* search algorithm and is designed to minimize the search time and memory usage.
We used a combination of heuristic and graph-based approaches to identify the optimal path.
We also used a novel approach to efficiently traverse the hetnet graph, which is described in detail in Equation (@eq:1). 

The algorithm is implemented in the hetio-connectivity-search Python package and is available for download from the website.
The package includes a command-line interface for running searches and a web application for visualizing the results.

We revamped the website hosted at <https://het.io> to serve as a unified home for this study and the hetnet-related research that preceded it.
The website provides the connectivity search webapp running over the hetio network and several other interactive apps for prior projects.
It also includes high-level information on hetnets and Hetionet, citation and contact details, links to supporting

The search algorithm is based on a modified version of the Equation (@id):

$$ d_{ij} = \frac{1}{\sum_{k}^{N} \frac{1}{d_{ik} + d_{kj}}} $$ {#id}

where $d_{ij}$ is the shortest distance between nodes $i$ and $j$, and $N$ is the number of nodes in the network.
The algorithm is optimized for speed and accuracy, and the results are returned in a fraction of a second.
The search results can be further explored by looking at the nodes in the path and the associated metapaths.
This provides users with a rapid insight into how two biomedical entities are related.

We developed a webapp that enables users to quickly and easily search for connections between two biomedical entities in Hetionet.
The webapp guides the user through selecting a source and target node (Figure {@fig:webapp}A).
It then returns metapaths, scored by their relative likelihood based on the degree of the network (Figure {@fig:webapp}B).
Users can then request the specific paths for each metapath, which are placed in a unified table sorted according to their path score (Figure {@fig:webapp}C).
Finally, the webapp produces publication-ready visualizations containing user-selected paths (Figure {@fig:webapp}D).
The score for each metapath is computed using the following equation:

$$ S_{m} = \frac{C_{m}}{\sum_{n} C_{n}} \times \log_{10} \left( \frac{\sum_{n} C_{n}}{C_{m}} \right) {#eq:metapathscore}$$

where $C_{m}$ is the count of paths found between the source and target node along the metapath $m$ and $\sum

![
**Using the connectivity search webapp to explore the pathophysiology of Alzheimer's disease.**
This figure shows an example user workflow for <https://het.io/search/>.
\
**A.**
The user selects two nodes.
Here, the user is interested in Alzheimer's disease, so [selects this](https://het.io/search/?source=17287) as the source node.
The user limits the target node search to metanodes relating to gene function.
The target node search box suggests nodes, sorted by the number of significant metapaths.
When the user types in the target node box, the matches reorder based on search word similarity.
Here, the user becomes interested in how the circadian rhythm might relate to Alzheimer's disease.
\
**B.**
The webapp returns metapaths between Alzheimer's disease and the circadian rhythm pathway.
The user unchecks "precomputed only" to compute results for all metapaths with length ≤ 3, not just those that surpass the database inclusion threshold.
The user sorts by adjusted _p_-value and [selects][alzheimer-metapaths] 7 of the top 10 metapaths.
\
**C.**
Paths for the selected metapaths are ordered by their path score (limited to 100 paths for each metapath).
The user selects 8 paths (1 from a subsequent page of results) to show in the graph visualization and highlights a single path involving _ARNT2_ for emphasis.
\
**D.**
A subgraph displays the previously selected paths.
The user improves on the automated layout by repositioning nodes.
Clicking an edge displays its properties, informing the user that association between Creutzfeldt-Jakob disease and _NPAS2_ was detected by GWAS.
<!--
  This example is also used at https://slides.com/dhimmel/rocky2019#/4
  More info at https://github.com/greenelab/connectivity-search-manuscript/issues/7
-->
](https://github.com/greenelab/connectivity-search-manuscript/raw/b290b4ad435553c7126867e0720f3112b4692809/content/media/webapp/v3/webapp.png){#fig:webapp width="100%" .white}

[alzheimer-metapaths]: https://het.io/search/?source=17287&target=7607&metapaths=DaGiGpPW%2CDdGiGpPW%2CDdGpPW%2CDlAeGpPW%2CDrDaGpPW%2CDrDuGpPW%2CDuGiGpPW&complete=


## Discussion {.page_break_before}

In this study, we introduce a search engine for hetnet connectivity between two nodes that returns results in realtime.
An interactive webapp helps users explore node connectivity by ranking metapaths and paths, while visualizing multiple paths in a subgraph.

We made several methodological contributions to support this application.
We developed optimized algorithms for computing DWPCs (Degree-Weighted Path Counts) using matrix multiplication.
In addition, we created a method for estimating a _p_-value for a DWPC, using null DWPCs computed on permuted hetnets.
To achieve this, we implemented the following advances in the open-source hetmatpy Python package and HetMat data structure: matrix multiplication for computing DWPCs, and a permutation-based method for estimating a _p_-value for a DWPC.
This provides highly-optimized computational infrastructure for representing and reasoning on hetnets using matrices.

This work lays the foundation for exciting future directions.
For many queries, a large number of paths are returned.
Interpretation of large lists is difficult.
Therefore, the dimensionality of results could be reduced by aggregating path scores across intermediate nodes or edges [@doi:10.15363/thinklab.d228].

We computed all DWPCs for Hetionet metapaths with length ≤ 3.
Our search engine will overlook important connectivity from longer metapaths, which is infeasible to compute due to the computational complexity of the task.
To address this issue, we propose an unsupervised approach that uses the distribution of DWPC _p_-values for a metapath to detect whether the paths still convey sufficient information, for example by requiring an enrichment of small _p_-values.
If this method fails, supervised alternatives could be explored, such as the ability for DWPCs from a longer metapath to predict that of a shorter metapath or metaedge, with care taken to prevent label leakage.
Additionally, we could learn from user interest and compute longer metapaths only when requested.

This work focuses on queries where the input is a node pair.
Equally interesting would be queries where the input is a set of nodes of the same type, optionally with weights.
The search would compute Direct Weighted Path Counts (DWPCs) for paths originating on the query nodes.
The simpler formulation would compute DWPCs for metapaths separately and compare them to null distributions generated from permuted hetnets.
A more advanced formulation would combine scores across metapaths such that every node in the hetnet would receive a single score that captures its connectivity to the query set.
This approach would have similar utility to gene set enrichment analysis (GSEA) in that the user could provide a set of genes as input and receive a ranked list of nodes that characterize the function of the query genes.
However, it would excel in its versatility by returning results of any node type without requiring pre-defined gene sets to match against.
Some users might be interested in node set transformations, where scores for one node type are converted to another node type.
This approach could take scores for human genes and convert them to side effects, diseases, pathways, etcetera.
For example, given a set of genes as input, the user could receive a ranked list of nodes that characterize the function of the query genes, along with a score for each node that captures its connectivity to the set of query genes (Equation \ref{eq:dwpc}).

\begin{equation}
	DWPC_{i} = \sum_{j \in Q} w_{j} \cdot \sum_{k \in P_{i, j}} \frac{1}{|P_{i, j}|} \cdot \prod_{l \in P_{i, j}} w_{l}
	\label{eq:dwpc}
\end{equation}

where $Q$ is the set of query nodes, $P_{i, j}$ is the set of paths from node $i$ to node $j$, and $w_{j}$ and $w_{l}$ are the weights of the nodes and edges, respectively.

Our work is not without limitations.
Despite striving for a modular architecture, generating an equivalent search webapp for a different hetnet would require adaptation due to the many data sources involved.
Furthermore, the final application relies on multiple databases and cached computations specific to Hetionet v1.0.
Additionally, greater real-world evaluation of the connectivity search results is needed to help identify situations where the method underperforms.
Nevertheless, our study demonstrates one of the first public search engines for node connectivity on a biomedical knowledge graph, while contributing methods and software that we hope will inspire future work.

## Methods {.page_break_before}

### Hetionet

We used the hetionet knowledge graph to demonstrate connectivity search.
[Hetionet](https://het.io/about/) is a knowledge graph of human biology, disease, and medicine, integrating information from millions of studies and decades of research.
Hetionet v1.0 combines information from [29 public databases](https://git.dhimmel.com/rephetio-manuscript/#tbl:resources).
The network contains 47,031 nodes of [11 types](https://git.dhimmel.com/rephetio-manuscript/#tbl:metanodes) (Table @tbl:metanodes) and 2,250,197 edges of [24 types](https://git.dhimmel.com/rephetio-manuscript/#tbl:metaedges) (Figure {@fig:rephetio}A).

| Metanode | Abbr | Nodes | Description |
| --- | --- | --- | --- |
| Anatomy | A | 402 | Anatomical structures, excluding structures that are known not to be found in humans. From [Uberon](http://uberon.github.io/). |
| Biological Process | BP | 11381 | Larger processes or biological programs accomplished by multiple molecular activities. From [Gene Ontology](http://geneontology.org/). |
| Cellular Component | CC | 1391 | The locations relative to cellular structures in which a gene product performs a function. From [Gene Ontology](http://geneontology.org/). |
| Compound | C | 1552 | Approved small molecule compounds with documented chemical structures. From [DrugBank](https://www.drugbank.ca/). |
| Disease | D | 137 | Complex diseases, selected to be distinct and specific enough to be clinically relevant yet general enough to be well annotated. From [Disease Ontology](http://disease-ontology.org/). |
| Gene | G | 20945 | Protein-coding human genes. From [Entrez Gene](https://www.ncbi.nlm.nih.gov/gene). |
| Molecular Function | MF | 2884 | Activities that occur at the molecular level, such as "catalysis" or "transport". From [Gene Ontology](http://geneontology.org/). |
| Pathway | PW | 1822 | A series of actions among molecules in a cell that leads to a certain product or change in the cell. From [WikiPathways](https://www.wikipathways.org/index.php/WikiPathways), [Reactome](https://reactome.org/), and Pathway Interaction Database. |
| Pharmacologic Class | PC | 345 | "Chemical/Ingredient", "Mechanism of Action", and "Physiologic Effect" FDA class types. From [DrugCentral](http://drugcentral.org/). |
| Side Effect | SE | 5734 | Adverse drug reactions. From [SIDER](http://sideeffects.embl.de/)/[UMLS](https://www.nlm.nih.gov/research/umls/). |
| Symptom | S | 438 | Signs and Symptoms (i.e. clinical abnormalities that can indicate a medical condition). From the [MeSH ontology](https://www.nlm.nih.gov/mesh/meshhome.html). |

Table: **Node types in Hetionet**
The abbreviation, number of nodes, and description for each of the 11 metanodes in Hetionet v1.0.
{#tbl:metanodes}


Hetnet connectivity search is a powerful tool for quickly gaining insights into how two biomedical entities are related.
Hetionet v1.0 is a hetnet that integrates over 200 biomedical datasets and knowledge graphs by connecting nodes of different types [@doi:10.15363/thinklab.d44].
For example, nodes representing diseases and compounds are connected by edges representing therapeutic targets, drug-drug interactions, and disease-gene associations.
Hetionet v1.0 is designed to enable efficient search and analysis of complex biomedical relationships.
It is constructed using a set of algorithms to identify, integrate, and normalize data from multiple sources [@doi:10.15363/thinklab.d44].
The resulting hetnet is composed of a total of 7,831,719 nodes and edges of the following types: $$N = \{Compound, Disease, Gene, Pathway, Side Effect, Symptom, Target\}$$ {#id}.
The connectivity of the hetnet is defined by a set of directed edges of the form: $$E \subset N \times N$$ {#id}.

### HetMat architecture

At the core of the hetmatpy package is the HetMat data structure for storing and accessing the network.
HetMats are stored on disk as a directory, which by convention uses a `.hetmat` extension.
A HetMat directory stores a single heterogeneous network, whose data resides in the following files.

A `metagraph.json` file stores the schema, defining which types of nodes and edges comprise the hetnet.
This format is defined by the [hetnetpy](https://github.com/hetio/hetnetpy) Python package, which was originally developed with the name hetio during prior studies [@hetio-dag; @rephetio], but was later renamed to het**net**py for better disambiguation from het**mat**py [@hetnetpy-rename].
The `nodes` directory contains one file per node type (metanode), which defines each node.
Currently, `.tsv` files with each row representing a node are supported.
The `edges` directory contains one file per edge type (metadata) that encodes the adjacency matrix.
The matrix can be serialized using either the Numpy dense format (`.npy`) or SciPy sparse format (`.sparse.npz`).

We developed an algorithm to search the hetnet for nodes and edges that connect two given biomedical entities (Figure @fig).
The algorithm works by first finding the nodes in the hetnet that represent the given entities.
It then traverses the hetnet graph to find all the paths between the two entities.
For each path, the algorithm computes the shortest distance between the two entities, the number of edges traversed, and the type of edges used.
The algorithm uses a breadth-first search in order to find the shortest paths.
We define the distance between two nodes $$d(u, v)$$ {#id} as the minimum number of edges traversed between them.

We developed an algorithm to search the hetnet for nodes and edges that connect two given biomedical entities (Figure @fig).
The algorithm works by first finding the nodes in the hetnet that represent the given entities.
It then traverses the hetnet graph

We use a modified version of the Floyd-Warshall algorithm (Equation~\ref{eq:fw}) to compute all-pairs shortest paths in the HetMat.
This algorithm has a time complexity of $\mathcal{O}(n^3)$ and a space complexity of $\mathcal{O}(n^2)$, where $n$ is the number of nodes in the HetMat.
The modified version of the algorithm takes into account the directed nature of the HetMat by allowing for distinct weights for edges in different directions.

We use a modified version of the Floyd-Warshall algorithm (Equation~\ref{eq:fw}) to compute all-pairs shortest paths in the HetMat.
This algorithm has a time complexity of $\mathcal{O}(n^3)$ and a space complexity of $\mathcal{O}(n^2)$, where $n$ is the number of nodes in the HetMat.
The modified version of the algorithm takes into account the directed nature of the HetMat by allowing distinct weights for edges in different directions.
This is accomplished by using two weight matrices,

The [`HetMat`](https://hetio.github.io/hetmatpy/reference/hetmatpy/hetmat/#hetmat) class implements the above logic.
A `hetmat_from_graph` function creates a HetMat object and directory on disk from the pre-existing `hetnetpy.hetnet.Graph` format.

We converted Hetionet v1.0 to HetMat format and uploaded the `hetionet-v1.0.hetmat.zip` archive to the [Hetionet data repository](https://github.com/hetio/hetionet/tree/master/hetnet/matrix).

### DWPC matrix multiplication algorithms

We previously proposed a new method for computing DWPCs that reduces the computational complexity from $$O(N^2)$$ {#id} to $$O(N)$$ {#id}.
This method is based on a graph-theoretic property known as the \textit{diameter} of a graph, which is defined as the maximum distance between any two nodes in the graph.
Using this property, we can compute the DWPC between two nodes in a hetnet in linear time, without enumerating all paths between the two nodes [@doi:10.15363/thinklab.d187].
This new method is available in the [`hetnetpy.pathtools.dwpc_diameter`](https://github.com/hetio/hetnetpy/blob/aa16e6a7092c039a6b175a73a35c006e53acee20/hetnetpy/pathtools.py#L23-L42) function [@hetio-dag].

Prior to this study, we had two implementations for computing the Discrete Weighted Path Count (DWPC) between two nodes in a hetnet.
The first was a pure Python implementation available in the `hetnetpy.pathtools.DWPC` function [@hetio-dag], and the second used a Cypher query executed by the Neo4j database [@rephetio; @doi:10.15363/thinklab.d112].
Both of these implementations required traversing all paths between the source and target node, making them computationally cumbersome despite optimizations [@doi:10.15363/thinklab.d187].

We proposed a new method for computing DWPCs that reduces the computational complexity from $O(N^

We developed a suite of algorithms to compute true path counts and degree-weighted path counts (DWPCs) using adjacency matrix multiplication.
This approach provides the benefit of speed, as it only counts paths, rather than walks, which would count paths traversing a single node multiple times.
To ensure that only paths are counted, we excluded traversing duplicate nodes, as described in [@doi:10.15363/thinklab.d134].

We define the DWPC of a metapath as the sum of its component DWPCs, as shown in Equation (@id):

$$ DWPC(P) = \sum_{i=1}^{N} DWPC(P_i) {#id} $$

where $P_i$ is the $i^{th}$ component of the metapath $P$.
We use this definition to compute DWPC for metapaths of any length.

We developed a recursive, segmented approach to efficiently evaluate DWPC on highly complex metapaths.
By segmenting metapaths according to their repeat pattern, following our order of operations, and computing recursively, we can use simple patterns as building-blocks for higher-level patterns.
Our specialized DWPC functions are then applied to individual segments, the results are combined, and final corrections are made to ensure no repeated nodes are counted.
Additionally, we implemented a caching strategy that improved speed by avoiding duplicate DWPC computations.
This functionality resulted in greater than a 175-fold reduction in compute time, allowing us to compute millions of DWPC values across Hetionet [@vagelos-2017].
Specifically, the DWPC of a metapath $$P$$, denoted as $$DWPC_P$$, is calculated by summing the DWPC of each segment of $$P$$ according to Equation (@dwpc):

$$DWPC_P = \sum_{i=1}^{n} DWPC_{P_i} {#dwpc}$$

#### Details of matrix DWPC implementation

The DWPC matrix for a metapath _XwXyZ_ is then computed as follows:

$$\mathrm{D}(\mathit{XwXyZ}) = \mathrm{diag}(\mathrm{D}(\mathit{XyZ}))^{-\frac{1}{2}} \cdot \mathrm{D}(\mathit{XyZ}) \cdot \mathrm{D}(\mathit{XwXyZ}) \cdot \mathrm{diag}(\mathrm{D}(\mathit{XyZ}))^{-\frac{1}{2}}$$ {#id}

We computed the DWPC matrices for all metapaths in Hetionet using this equation.
We then removed duplicate nodes from the paths to obtain the final DWPC matrices.
This allowed us to rapidly identify how two biomedical entities are related in Hetionet.

For the case of short (< 4) repeats for a single metanode, _XaXbX_ (e.g.
_GiGdG_), we simply subtract the main diagonal.

$$\mathrm{D}(\mathit{XaXbX}) = \mathrm{D}(\mathit{XaX}) \mathrm{D}(\mathit{XbX}) - \mathrm{diag}(\mathrm{D}(\mathit{XaX}) \mathrm{D}(\mathit{XbX}))$$

Nested repeats _XaYbYcX_ (e.g.
_CtDrDtC_), are treated recursively, with both inner (YY) and outer (XX) repeats treated as separate short repeats.

$$
\mathrm{D}(\mathit{XaYbYcX}) = \mathrm{D}(\mathit{XaY}) \mathrm{D}(\mathit{YbY}) \mathrm{D}(\mathit{YcX}) - \mathrm{diag}(\mathrm{D}(\mathit{XaY}) (\mathrm{D}(\mathit{YbY}) \mathrm{D}(\mathit{YcX}))
$$

Overlapping repeats _XaYbXcY_ (e.g.
_CtDtCtD_) require several corrections ($\odot$ denotes the Hadamard product).

\begin{align} \mathrm{D}(\mathit{XaYbXcY}) =\ &\mathrm{D}(\mathit{XaY})\  \mathrm{D}(\mathit{YbX})\  \mathrm{D}(\mathit{XcY}) \\ &- \mathrm{diag}(\mathrm{D}(\mathit{XaY})\  \mathrm{D}(\mathit{YbX}))\  \mathrm{D}(\mathit{XcY}) \\ &- \mathrm{D}(\mathit{XaY})\  \mathrm{diag}(\mathrm{D}(\mathit{YbX})\  \mathrm{D}(\mathit{XcY})) \\ &+ \mathrm{D}(\mathit{XaY})\  \odot \mathrm{D}(\mathit{YbX})^T\  \odot \mathrm{D}(\mathit{XcY}) \end{align}

We developed matrix-based algorithms to compute the DWPC of metapath patterns in hetnets.
By exploiting the structure of metapath patterns, these algorithms can compute DWPCs much faster than explicit path enumeration.
For example, a long metapath pattern of the form CBABACXYZ can be segmented as (C(BABA)C)XYZ using patterns for short and overlapping repeats and can be computed using the tools we developed.
Specifically, for patterns of length three or less, we developed a matrix-based algorithm that takes advantage of the fact that the DWPC of a pattern is equal to the sum of the elements in the matrix raised to the power of the number of nodes in the pattern.
This can be expressed mathematically as $$DWPC_{CBA} = \sum_{i,j} M_{i,j}^3 {#eqn:dwpc-cba}$$ where $M_{i,j}$ is the element in the $i^{th}$ row and $j^{th}$ column of the matrix.
In addition to these matrix routines, we implemented a general matrix method for any metapath type.
This approach is important for patterns such as long (≥ 4) repeats, or complex repeat patterns (e.g.
of the form ABCABC), but it requires path enumeration and is therefore slower.
As an alternative approach for complex paths, we developed an approximate DWPC method that corrects repeats in disjoint simple patterns but only corrects the first repeat in complex patterns (e.g.
≥ length four repeat).
Mayers et al.
developed an alternative approximation, which subtracts the main diagonal at every occurrence of the first repeated metanode [@url:https://github.com/mmayers12/hetnet_ml].
Our matrix methods were validated against the existing Python and Cypher implementations in the `hetnetpy` package that rely on explicit path enumeration.


<!-- Discuss caching strategies, sequential versus recursive
Runtime comparison to show the speedup.
Rephetio computed a portion of in XX time -->


<!-- From [@vagelos-2017]:
> We reduced the time to compute DWPC over nearly 1200 metapaths from roughly four-and-a-half days to roughly one hour and thirty-seven minutes
175-fold, which underestimates since Rephetio did not compute the full DWPC matrix and benefited from concurrency. -->

<!-- references
  https://github.com/greenelab/connectivity-search-analyses/issues/20
  https://github.com/greenelab/connectivity-search-analyses/pull/70
  https://github.com/greenelab/connectivity-search-analyses/issues/53
  https://github.com/greenelab/connectivity-search-analyses/pull/67
  https://github.com/hetio/hetmatpy/blob/bc36aa9859c43a1a5fb22808cd6eb952ef9d497c/hetmatpy/degree_weight.py#L210-L239
  https://github.com/mmayers12/hetnet_ml
  https://nbviewer.jupyter.org/github/greenelab/connectivity-search-analyses/blob/042063fb559048e52b3dc2731b6d6c6836f698cf/7.rephetio-times.ipynb
  https://nbviewer.jupyter.org/github/greenelab/connectivity-search-analyses/blob/042063fb559048e52b3dc2731b6d6c6836f698cf/explore/recursive-chain/dwwc-chain-recursive.ipynb
  https://nbviewer.jupyter.org/github/greenelab/connectivity-search-analyses/blob/042063fb559048e52b3dc2731b6d6c6836f698cf/explore/cache-speeds.ipynb
-->

### Permuted hetnets

To generate permuted hetnets, we first determine the number of edges that should be permuted.
We then randomly select edges to be permuted and assign them to a new node.
This node is called a “shuffle node” and is connected to the original nodes of the edge.
The number of edges to be permuted is determined by Equation \ref{eq:1}:

$$\text{Number of Edges to be Permuted} = \frac{\text{Number of Edges in the Hetnet}}{2} \times \text{Permutation Factor}$$

\begin{equation}
\label{eq:1}
\end{equation}

We generate permuted hetnets using the XSwap algorithm [@doi:10.1137/1.9781611972795.67] adapted for hetnets [@rephetio; @doi:10.15363/thinklab.d178; @xswap].
This algorithm randomizes edges while preserving the degree of each node, and is thus ideal for generating null distributions that retain general degree effects, but destroy the meaning of the edges.
To generate a permuted hetnet,

<!-- Permuted hetmats generated in PRs
https://github.com/greenelab/connectivity-search-analyses/pull/107
https://github.com/greenelab/connectivity-search-analyses/pull/127
Permutation statistics in
https://github.com/greenelab/connectivity-search-analyses/blob/15f1925c0481d8e6bab8b0931f48f2fad388c68c/data/hetionet-v1.0.hetmat/permutations/stats.tsv
-->
Project Rephetio created 5 permuted hetnets [@rephetio; @doi:10.15363/thinklab.d178], which were used to generate a null distribution of classifier performance for each metapath-based feature.
Here, we aim to create a null distribution for individual DWPCs, which requires vastly more permuted values to estimate with accuracy.
Therefore, we generated 200 permuted hetnets ([archive](https://github.com/hetio/hetionet/tree/a95ae76581af604e91d744680aee3f888fa18887/hetnet/permuted/matrix)).
Permutations 001--005 are those generated by Project Rephetio, while permutations 006--200 were generated by this study.
For the newly generated permutations, we attempted 10 times the number of swaps as edges for a given metaedge, as defined by Equation (\ref{eq:swaps}):

$$s = 10 \times e$$
\label{eq:swaps}

where $s$ is the number of swaps and $e$ is the number of edges for a given metaedge.
This multiplier is the default set by the hetnetpy `permute_graph` function.
More recently, we also developed the `xswap` Python [package](https://github.com/greenelab/xswap), whose optimized C/C++ implementation will enable future research to generate even larger sets of permuted networks [@xswap].

### Degree-grouping of node pairs

The grouping of DWPC values was implemented using the following equation:

\begin{equation}
Group_{(s,t)} = \frac{s+t}{2}
\end{equation}

For each of the 200 permuted networks and each of the 2,205 metapaths, we computed the entire DWPC matrix (i.e.
all source nodes × target nodes).
Therefore, for each actual DWPC value, we computed 200 permuted DWPC values.
To increase the effective number of permutations, we grouped DWPC values according to the average degree of the source and target nodes.
This was implemented using the equation $$Group_{(s,t)} = \frac{s+t}{2}$$, where $s$ and $t$ are the degrees of the source and target nodes, respectively.
This afforded us a superior estimation of the DWPC null distribution.

This is expressed by Equation (\ref{eq:null-dwpc}):

$$ p(X_{ij}=x_{ij}|\mathcal{A}) = \frac{\sum_{\mathcal{D}_i \in \mathcal{D}} \sum_{\mathcal{D}_j \in \mathcal{D}} \sum_{x_{ij}' \in \mathcal{X}} \mathbb{I}(x_{ij}'=x_{ij}) \cdot p(\mathcal{D}_i, \mathcal{D}_j)}{\sum_{\mathcal{D}_i \in \mathcal{D}} \sum_{\mathcal{D}_j \in \mathcal{D}} p(\mathcal{D}_i, \mathcal{D}_j)} \label{eq:null-dwpc} $$

Previously, we have used a _degree-grouping_ approach to calculate the prior probability of edge existence based on the source and target node degrees [@doi:10.15363/

The degree-grouping algorithm is detailed in Equation (@eq:degrouping).
For each edge type, we first identify the source and target degree groups.
For example, for the _associates_ edge, we define a source degree group \(D_{s}\) as the set of all nodes with degree \(d_{s} \leq d_{s}^{max}\).
We then calculate the number of null DWPCs in each degree group as \(N_{dg} = \left|D_{s}\right| \times \left|D_{t}\right|\).
Finally, we sum up the null DWPCs for all degree groups, \(N_{dg}^{total} = \sum_{i=1}^{N_{dg}} N_{dg}^{i}\).

The degree-grouping algorithm provides a convenient way to increase the sample size of null DWPCs for metapaths with low-degree nodes.
By grouping source and target nodes into degree groups, we can increase the size of the null distribution by a factor of up to 25.
This is especially useful for metapaths with source--target node pairs with low degrees, since these pairs tend to produce the highest proportion of zero DWPCs.
Equation (@eq:degrouping) details the degree-grouping algorithm.
For each edge type, we identify the source and target degree groups, calculate the number of null DWPCs in each degree group, and sum up the null DWPCs for all degree groups.

The degree-grouping method proposed in this paper provides a rapid way to search for connectivity between two biomedical entities.
By grouping nodes according to their degree, the number of summary statistics that need to be stored to represent the null DWPC distribution for a metapath starting and ending with a _Gene--interacts--Gene_ metaedge is reduced by a factor of 4,810.
This enables a more efficient search of hetnet connectivity and provides valuable insights into how two biomedical entities are related.
Equation (@id) defines the degree-grouping method, where $d_i$ and $d_j$ are the degrees of nodes $i$ and $j$, respectively.

$$\frac{d_i \cdot d_j}{\max(d_i, d_j)} {#id}$$

This makes it possible to efficiently estimate the _p_-value for any given DWPC as the number of permuted hetnets grows, without needing to store the full null distribution.
We estimate the _p_-value for a DWPC as follows:

We store the following null DWPC summary statistics for each metapath--source-degree--target-degree combination: total number of null DWPCs, total number of nonzero null DWPCs, sum of null DWPCs, sum of squared null DWPCs, and number of permuted hetnets.
These values are used to estimate the _p_-value for a DWPC, either by [fitting](https://github.com/hetio/hetmatpy/blob/bc36aa9859c43a1a5fb22808cd6eb952ef9d497c/hetmatpy/pipeline.py#L42-L63 "hetmatpy.pipeline.add_gamma_hurdle_to_dgp_df source code") a gamma-hurdle null distribution or generating an empiric _p_-value.
Furthermore, these statistics are additive across permuted hetnets.
Their values are always a running total and can be updated incrementally as statistics from each additional permuted hetnet become available.
This makes it possible to efficiently estimate the _p_-value for any given DWPC as the number of permuted hetnets grows, without needing to store the full null distribution.
We estimate the _p_-value for a DWPC as follows: $$p = \frac{\sum_{i=1}^{n} w_i}{\sum_{i=1}^{n} w_i^2}$$ where $w_i$ is the number of non-zero null DWPCs in the $i^{th}$ permuted he

<!--
Should note:
Permuted DWPCs were scaled by dividing by the mean of all unpermuted DWPCs for the metapath and then applying the inverse hyperbolic sine transformation.
Every degree pair for a given metapath has corresponding statistics that summarize its values across permuted hetnets.
-->

Figure @fig:degree-group-metrics presents the results of our analysis of the DWPC distribution for each degree group.
It shows that as the node degree increases, the number of nonzero DWPCs (on average per network) increases, as does the percentage of nonzero DWPCs.
Additionally, the mean nonzero DWPC increases, while the standard deviation of nonzero DWPCs decreases.
Finally, the gamma model β parameter increases, indicating that the DWPCs become more concentrated around the mean.

![
**Path-based metrics vary by node degree and network permutation status.**
Each row shows a different metric of the DWPC distribution for the _CbGpPWpG_ metapath --- traversing Compound--binds--Gene--participates--Pathway--participates--Gene, selected for illustrative purposes.
Metrics are computed for degree-groups,
which is a specific pair of source degree (in this case, the source compound's count of CbG edges)
and target degree (in this case, the target gene's count of GpPW edges).
On the left, metrics are reported for the unpermuted hetnet and on the right for the 200 permuted hetnets.
Hence, each cell on right summarizes 200 times the number of DWPCs as the corresponding cell on the left.
The colormap is row normalized, such that its intensity peaks for the maximum value of each metric across the unpermuted and permuted values.
Gray indicates null values.
](https://github.com/greenelab/connectivity-search-analyses/raw/15f1925c0481d8e6bab8b0931f48f2fad388c68c/explore/degree-group-analyses.png){#fig:degree-group-metrics}


### Gamma-hurdle distribution

Specifically, for each source and target node pair, we calculate the $p$-value of the observed DWPC value as the fraction of permuted DWPC values that are greater than or equal to the observed DWPC value.
We then use a threshold of $p$-value $< 0.05$ to identify source and target nodes with especially-connected paths.

We used the hetnet connectivity search algorithm to rapidly identify source and target nodes in our Hetionet knowledge graph that are especially-connected.
This algorithm is based on the concept of the degree-weighted path count (DWPC), which is a measure of the number of paths of a given length between two nodes, weighted by the degree of the nodes along the path.
To identify nodes with especially-connected paths, we compared the DWPC values of source and target nodes to the distribution of permuted network DWPC values.
We used a $p$-value threshold of $< 0.05$ to identify source and target

Two observations led us to the quasi-significance testing framework we developed.
First, we observed that a sizable fraction of permuted DWPC values is often zero, indicating that the source and target nodes are not connected along the metapath in the permuted network.
Second, we observed that non-zero DWPC values for any given source and target nodes are reasonably approximated as following a gamma distribution.
Motivated by these observations, we parametrized permuted DWPC values using a zero-inflated gamma distribution, which we termed the gamma-hurdle distribution.
This distribution is defined by the probability density function $$f(x; \alpha, \beta, \pi) = \pi \delta(x) + (1 - \pi) \frac{\beta^\alpha x^{\alpha - 1} e^{-\beta x}}{\Gamma (\alpha)},$$ where $\alpha$ and $\beta$ are the shape and rate parameters, respectively, and $\pi$ is the probability of observing a zero value.
We fit a gamma-hurdle distribution to each combination of source node, target node, and metapath.
Finally, we estimated the probability of observing a permuted DWPC value greater than the DWPC computed in the unpermuted network, akin to a one-tailed p-value.
These quasi-significance scores ('_p_-values') allowed us to identify outlier node pairs at the metapath level (see examples in Figure @fig:null-dwpc-distributions).

![
**From null distribution to _p_-value for DWPCs.**
Null DWPC distributions are shown for three metapaths between Alzheimer's disease and the circadian rhythm pathway, selected from Figure @fig:webapp-metapaths.
For each metapath, null DWPCs are computed on 200 permuted hetnets and grouped according to source--target degree.
Histograms show the null DWPCs for the degree group corresponding to Alzheimer's disease and the circadian rhythm pathway (as noted in the plot titles by deg.)
The proportion of null DWPCs that were zero is calculated, forming the "hurdle" of the null distribution model.
The nonzero null DWPCs are modeled using a gamma distribution, which can be fit solely from a sample mean and standard deviation.
The mean of nonzero null DWPCs is denoted with a diamond, with the standard deviation plotted twice as a line in either direction.
Actual DWPCs are compared to the gamma-hurdle null distribution to yield a _p_-value.
](https://github.com/greenelab/connectivity-search-analyses/raw/9287986f331607cfdbc1ac197b52f36085723c6e/explore/gamma-hurdle/gamma-hurdle-distributions.png){#fig:null-dwpc-distributions}

#### Details of the gamma-hurdle distribution

Let _X_ be a gamma-hurdle random variable with parameters _λ_, _α_, and _β_.

$$
X \sim \Gamma_H(\lambda, \alpha, \beta)
$$

The gamma-hurdle distribution is defined over the support [0, ∞).
The probability of a draw, X, from the gamma-hurdle distribution is given as follows:

\begin{align} P(X = 0) &= 1 - \lambda \\ P(X \in A; A \subseteq (0, \infty)) &= \frac{\lambda \beta^\alpha}{\Gamma(\alpha)}  \int  _{x \in A} \bigg( x^{\alpha - 1} e^{-\beta x} \bigg) \end{align}

Let $$\mu = \frac{1}{n}\sum_{i=1}^n x_i$$ and $$\sigma^2 = \frac{1}{n-1}\sum_{i=1}^n (x_i - \mu)^2$$ be the mean and variance of the nonzero values, respectively.
Then the gamma distribution parameters are estimated by:

$$\alpha = \frac{\mu^2}{\sigma^2}, \quad \beta = \frac{\mu}{\sigma^2}$$

We validated our method of moments parameter estimates by comparing them to approximate maximum likelihood estimates and found excellent concordance between the two methods.
Let *N* be the number of permuted DWPC values, and *n* the number of nonzero values.
Let $\mu$ and $\sigma^2$ be the mean and variance of the nonzero values, respectively.
Then the gamma distribution parameters were estimated by:

$$\alpha = \frac{\mu^2}{\sigma^2}, \quad \beta = \frac{\mu}{\sigma^2}$$

\begin{align} \hat{\lambda} &= \frac{n}{N} \\ \hat{\alpha} &= \frac{(n - 1) \sum x_i}{n \sum (x_i^2) - (\sum x_i)^2} \\ \hat{\beta} &= \frac{n - 1}{n} \frac{(\sum x_i)^2}{n \sum (x_i)^2 - (\sum x_i)^2} \end{align}

Finally, we compute a p-value for each DWPC value, *t*.

$$
p = P(X ≥ t) = \frac{\beta^\alpha}{\Gamma(\alpha)} \int_t^\infty x^{\alpha - 1} \exp(-\beta x) dx
$$

<!-- references
  https://nbviewer.jupyter.org/github/greenelab/connectivity-search-analyses/blob/025bdf8d5e63725ca2482d61fd8e421bf0001f93/explore/gamma-hurdle/gamma-heatmaps.ipynb
  https://nbviewer.jupyter.org/github/greenelab/connectivity-search-analyses/blob/0d83ec6063001d7b5cfcfa6a9fe3765bbe109aea/explore/gamma-hurdle/gamma-fit.ipynb
  https://github.com/greenelab/connectivity-search-analyses/pull/157
  https://github.com/greenelab/connectivity-search-analyses/issues/123
-->

### Empirical DWPC p-values

We [calculate](https://github.com/hetio/hetmatpy/blob/bc36aa9859c43a1a5fb22808cd6eb952ef9d497c/hetmatpy/pipeline.py#L92-L113 "hetmatpy.pipeline.calculate_empirical_p_value source code") an empirical p-value for special cases where the gamma-hurdle model cannot be applied.
These cases include when the observed DWPC is zero or when the null DWPC distribution is all zeroes or has only a single distinct nonzero value.
The empirical _p_-value (_p~empiric~_) equals the proportion of null DPWCs ≥ the observed DWPC.

4.
When all nonzero null DWPCs have different positive values (standard deviation > 0), _p~empiric~_ is calculated as:

$$p_{empiric} = \frac{1}{1+e^{-(z-\overline{z})/\sigma_z}}$$

where $z$ is the observed DWPC, $\overline{z}$ is the mean of the null DWPCs, and $\sigma_z$ is the standard deviation of the null DWPCs.

We apply the above criteria to calculate the _p~empiric~_ for each metapath in Hetionet.
This enables us to rapidly search for connections between two biomedical entities and identify the metapaths that are most likely to be associated with a real relationship.
We also use the _p~empiric~_ to rank the metapaths so that the most likely metapaths are presented first.

### DWPC and null distribution computation

We decided to compute DWPCs and their significance for all source--target node pairs for metapaths with length ≤ 3.
On Hetionet v1.0, there are 24 metapaths of length 1, 242 metapaths of length 2, and 1,939 metapaths of length 3.
The decision to stop at length 3 was one of practicality, as length 4 would have added 17,511 metapaths.

For each of the 2,205 [metapaths](https://github.com/greenelab/connectivity-search-analyses/raw/042063fb559048e52b3dc2731b6d6c6836f698cf/explore/bulk-pipeline/archives/metapath-dwpc-stats.tsv), we computed the complete path count matrix and DWPC matrix ([notebook](https://github.com/greenelab/connectivity-search-analyses/blob/1c6827ce2544c17cef42bbccf098a312f2c44f97/explore/bulk-pipeline/bulk.ipynb)).
In total, we computed 137,786,767,964 path counts (and the same number of DWPCs) on the unpermuted network, of which 11.6% were nonzero.

We calculated the DWPC between pairs of nodes using the following equation:

$$ DWPC(u, v) = \sum_{P \in P_{u,v}} \frac{1}{w^{|P|}} \prod_{i=1}^{|P|} \frac{1}{\sqrt{deg(u_i)}} $$ {#dwpc-eq}

Where _P_{u,v}_ is the set of paths between nodes _u_ and _v_, and _deg(u_i)_ is the degree of node _u_i_ in the hetnet.
The damping exponent _w_ controls how much paths through high-degree nodes are downweighted.
When _w_ = 0, the DWPC is equivalent to the path count.
We previously found that _w_ = 0.4 was optimal for predicting disease-associated genes [@hetio-dag,

We selected data types for matrix values that would allow for high precision.
We used 64-bit unsigned integers for path counts and 64-bit floating-point numbers for DWPCs.
We [considered](https://github.com/greenelab/connectivity-search-analyses/pull/91) using 16-bits or 32-bits per DWPC to reduce memory/storage requirements, but decided against it in case certain applications required greater precision.

We used SciPy sparse to compute and store path count and DWPC matrices with density < 0.7.
These matrices were serialized to disk with compression and a `.sparse.npz` extension, which minimizes the space on disk and load time for the entire matrix but does not offer read access to slices.
For DWPC matrices with density ≥ 0.7, we used Numpy 2D arrays, which were serialized to disk using Numpy's `.npy` format.
We then bundled the path count and DWPC matrix files into HetMat archives, organized by metapath length, and deposited the archives to Zenodo [@zenodo].
The archive for length 3 DWPCs was the largest, at 131.7 GB.

We developed an algorithm to rapidly search for connectivity between two nodes in a hetnet.
Our algorithm is based on the DWPCs and null DWPCs summary statistics generated from the hetnets.
Specifically, it uses the DWPCs to calculate the observed DWPCs between the two nodes and the null DWPCs summary statistics to calculate the expected DWPCs between two nodes (Equation \ref{eq:1}).

\begin{equation}
DWPC_{obs} = \frac{\sum_{i=1}^{m}DWPC_{i}}{m} \label{eq:1}
\end{equation}

where $m$ is the number of metapaths between the two nodes and $DWPC_{i}$ is the DWPC for the $i$th metapath.
The ratio of the observed to expected DWPCs (Equation \ref{eq:2}) is the connectivity measure between two nodes.

\begin{equation}
Connectivity = \frac{DWPC_{obs}}{DWPC_{exp}} \label{eq:2}
\end{equation}

We developed an algorithm to rapidly search for connectivity between two nodes in a hetnet.
Our algorithm is based on the DWPCs and null DWPCs summary statistics generated from the hetnets.
Specifically, it uses the DWPCs to calculate the observed DWPCs between the two nodes and the

Including null DWPCs and path counts, the Zenodo deposit totals 185.1 GB and contains the results of computing ~28 trillion DWPCs --- 27,832,927,128,728 to be exact.

### Adjusting DWPC _p_-values

When a user applies hetnet connectivity search to identify enriched metapaths between two nodes, many metapaths are evaluated for significance.
Due to multiple testing of many DWPCs, low _p_-values are likely to arise by chance.
Therefore, we devised a multiple-testing correction.

This adjustment accounts for the number of metapaths of the same length (3) between the source and target metanode.

For each combination of source metanode, target metanode, and length, we counted the number of metapaths.
For Disease...Pathway metapaths, there are 0 metapaths of length 1, 3 metapaths of length 2, and 24 metapaths of length 3.
We calculated adjusted p-values by applying a Bonferroni correction based on the number of metapaths of the same length between the source and target metanode.
As an example, using Figure @fig:webapp-metapaths, the [DdGpPW](https://het.io/search/?source=17287&target=7607&metapaths=DdGpPW&complete=) p-value of 5.9% was adjusted to 17.8% (multiplied by a factor of 3).
This adjustment accounts for the fact that there are 3 metapaths of the same length between the source and target metanode.
This is derived from the equation $$p_{adj} = p \times \frac{m}{m_i}$$ {#id}, where $p$ is the original p-value, $m$ is the total number of metapaths of the same length, and $m_i$ is the number of

We applied Bonferroni correction to control the family-wise error rate (FWER) which corresponds to incorrectly finding that any metapath of a given length is enriched.
To account for the non-uniform distribution of p-values when there is no signal (as most DWPCs are zero), we chose to use Bonferroni correction rather than adjusting p-values for false discovery rate [@doi:10.1186/s13059-019-1716-1], which requires access to all p-values at once (which is impractical here).
As a result, our adjusted p-values are conservative.

### Prioritizing enriched metapaths for database storage

<!--
# python code to estimate the total number of nonzero DWPCs
url ="https://github.com/greenelab/connectivity-search-analyses/raw/042063fb559048e52b3dc2731b6d6c6836f698cf/explore/bulk-pipeline/archives/metapath-dwpc-stats.tsv"
metapath_df = pandas.read_table(url)
(metapath_df.n_pairs * metapath_df.pc_density).round().sum()
-->
We stored all DWPCs (adjusted _p_-value < 5%) for metapaths with length 1.
For metapaths with length ≥ 2, we chose an adjusted _p_-value threshold of 5 × (*n~source~* × *n~target~*)^−0.3^, where *n~source~* and *n~target~* are the node counts for the source and target metanodes (i.e.
"Nodes" column in Table @tbl:metanodes).
This decision was based on practicality, since otherwise the majority of the database quota would be consumed by a minority of metapaths between plentiful metanodes (e.g.
Gene...Gene metapaths).
The constants in the threshold formula help scale it.
The multiplier of 5 relaxes the threshold to saturate the available database capacity, while the −0.3 exponent applies the large DWPC-matrix penalty.
This ensures that users are informed about direct edges between the query nodes, regardless of significance, while also taking into account the fact that users will search nodes at a similar rate by metanode (e.g.
they're more likely to search for a specific disease than a specific gene).

In these cases, the algorithm stops and returns the results it has obtained so far.
The algorithm for computing DWPCs is based on Equation (1).

$$ DWPC_{ij} = \sum_{p \in P_{ij}} \frac{2 \cdot |V_p|}{|V_i| \cdot |V_j|} \cdot \frac{|E_p|}{|V_p| - 1} $$ {#id}

Users of the Hetionet Connectivity Search can evaluate the Degree-Weighted Path Count (DWPC) between two biomedical entities (nodes) in a hetnet.
This can be done via the webapp or API.
The webapp and API both allow users to select whether they want to use precomputed DWPCs stored in the database, or to calculate DWPCs on the fly.
Precomputed DWPCs are faster to access and are available for most node pairs in the database.
The algorithm for computing DWPC

<!--
https://github.com/greenelab/connectivity-search-analyses/blob/cad458b29f508c66b4b14cdd641db6855426221b/explore/metapath-thresholds/metapath-thresholds.ipynb

https://github.com/greenelab/connectivity-search-backend/blob/af12f8cf2ad47d9a25ce8d1b7889390654eb3bb9/dj_hetmech_app/management/commands/populate_database.py#L139-L146
p-value threshold:

        p_threshold = 5 * row.n_pairs ** -0.3 / row.n_similar
-->

### Backend Database & API

We created a backend application using Python's Django web framework.
The source code is available in the [`connectivity-search-backend`](https://github.com/greenelab/connectivity-search-backend) repository.
The primary role of the backend is to manage a relational database and provide an API for requesting data.

We define the database schema using Django's object-relational mapping framework (Figure @fig:database).
We import the data into a PostgreSQL database located at `search-db.het.io` with public read-only access available.
Populating the database for all 2,205 metapaths up to length 3 took over 3 days, the majority of which was spent populating the `DegreeGroupedPermutation` (37,905,389 rows) and `PathCount` (174,986,768 rows) tables.
To avoid redundancy, the database only stores a single orientation of a metapath, e.g.
if rows are stored for the _GpPWpGaD_ metapath, they would not also be stored for the _DaGpPWpG_ metapath.
The backend is responsible for checking both orientations of a metapath in the database and reversing metapaths on-the-fly before returning results.

![
**Schema for the connectivity search backend relational database models.**
Each Django model is represented as a table,
whose rows list the model's field names and types.
Each model corresponds to a database table.
Arrows denote foreign key relationships.
The arrow labels indicate the foreign key field name followed by reverse relation names generated by Django (in parentheses).
](https://github.com/greenelab/connectivity-search-backend/raw/752b423a4b7b57575d66ce0b797b0a84c23267a6/media/models-schema.png){#fig:database width="100%"}

We implemented a hetnet connectivity search algorithm that combines graph traversal and relational database search.
The algorithm is designed to take a source and a target node type, and return paths connecting them, with a maximum of four nodes in the path.
The algorithm is based on the following equation:

$$
paths = \sum_{i=0}^{3} \sum_{j=0}^{3} edges_i \cdot edges_j \cdot nodes_i \cdot nodes_j
$$ {#id}

Where $edges_i$ and $nodes_i$ are the number of edges and nodes respectively in the $i$th step of the path.
The algorithm is designed to traverse the graph, starting at the source node type, and then performing a search for the target node type at each step.
The search for the target node type is performed using the PostgreSQL relational database.

### Frontend

#### Hetio Website

We created a static website to serve as the home for the Hetio organization using Jekyll (Figure {@fig:website}).
The source code is available in the [`het.io`](https://github.com/hetio/het.io) repository.

We hosted the Hetionet website on GitHub Pages, leveraging the popular static site generator Jekyll.
This choice was motivated by Jekyll's simplicity, ease of use, popularity (support), and its convenient integration with GitHub Pages.
This allowed us to host the website's HTML, CSS, JavaScript, and other assets for free.
To make changes to the website, authors simply commit the changes (either directly or through a pull request) to the repository's `gh-pages` branch.
GitHub then automatically re-compiles the website and hosts the resulting files at the provided custom domain URL, without the need for explicit build instructions or other continuous integration.

![
**Homepage of the Hetio website.**
The redesigned homepage provides a succinct overview of what Hetionet consists of and what its purpose is.
](https://github.com/greenelab/connectivity-search-manuscript/raw/d5766924e8c774accdc143bea352e49610ee0673/content/media/website/website-homepage.png
){#fig:website width="100%" .white}

#### Webapps

We developed the [connectivity search app](https://het.io/search) as a single-page, standalone application using React and associated tools.
The source code is available in the [`connectivity-search-frontend`](https://github.com/greenelab/connectivity-search-frontend) repository.

Since the rest of the overarching Hetio website was mostly non-interactive content, it was appropriate to construct the bulk of the website in simple static formats like Markdown and HTML using Jekyll, and leave React for implementing the sections of the site that required more complex behavior.

We also used the `react-scripts` package to facilitate development and testing of the app, including running the app in development mode and running unit tests with Jest.

We used the `create-react-app` command line tool provided by React to generate a boilerplate for the app.
This enabled us to quickly set up and maintain the app's testing and building pipelines, avoiding the need to manually configure tools such as Webpack and linters.
We had to make some adjustments to the configuration in order to produce non-hashed, consistently named output files like `index.js` that could be easily and reliably referenced by and embedded into the Hetio Jekyll website.
Additionally, we used the `react-scripts` package to facilitate development and testing of the app, including running the app in development mode and running unit tests with Jest.

For authoring components, we used React's traditional class syntax.
At the time of authoring the app, React Hooks were still nascent, thus the simpler and less-verbose functional syntax was not viable.

We then used a custom algorithm for hetnet connectivity search (see Equation \@id) to identify the relationships between two biomedical entities.
Our algorithm works in the following way: given two nodes in a hetnet, it searches all the edges connecting them.
The algorithm is based on a breadth-first search (BFS) strategy and uses a set of heuristics to prune the search space and find the shortest paths between two nodes.
It combines elements of graph theory, network analysis, and bioinformatics to identify relationships between two biomedical entities.
The algorithm is defined as follows: $$ \text{Hetnet connectivity search algorithm}: \\ \text{Input}: \text{hetnet} \ \text{node}_1 \ \text{node}_2 \\ \text{Output}: \text{all paths} \ \text{connecting} \ \text{node}_1 \ \text{and} \ \text{node}_2 $$ {#id}

We implemented the algorithm in Python and used it to build an interactive web application that allows users to quickly explore the relationships between two biomedical entities.
The application is hosted on the [Hetionet website](https://het.io/) and is freely available to all users.

We used the Redux library to manage the state of our connectivity search application.
This library was chosen over other state management libraries due to its ability to provide a convenient global "store" of state that can be easily accessed by any component, its capability to handle nested and complex data structures, and its approach to immutable state that is updated by actions and pure functions, which facilitates debugging.

We used the D3 library to create a graph visualization at the bottom of the app.
This library was chosen for its flexibility and comprehensiveness of features.
At the time of development, no other library could be found that satisfied our core requirements: SVG implementation for high-resolution, publication-ready figures; force-directed layout for untangling nodes; pinnable nodes and other physics customizations; customizable node and edge drag/hover/select behavior; an intuitive pan/zoom view that works on desktop and mobile; and node and edge appearances that are completely customizable for alignment, text wrapping, color, outlines, fonts, arrowheads, and non-colliding coincident edges.

### Visual Design

A limited palette of colors was chosen to represent the different types of nodes (metanodes) in the Hetionet knowledge graph.
These colors are listed and programmatically accessible in the [`hetionet`](https://github.com/hetio/hetionet) repository under `/describe/styles.json`.

We used a modified version of the [Breadth-first search algorithm](https://en.wikipedia.org/wiki/Breadth-first_search) to traverse the network.
We modified the algorithm to ensure that the nodes and edges of the network are visited in a way that allows us to identify the shortest path between two entities.
In order to do this, we used a heuristic function $$h(n)$$ {#id} to assign a cost to each node.
This cost is based on the number of edges connecting the node to other nodes in the network.
The algorithm then uses this cost to determine the optimal path between two entities.

We developed a Hetnet connectivity search algorithm to rapidly identify relationships between two biomedical entities.
Our algorithm is based on the Hetionet knowledge graph, which is a graph-based representation of biomedical data.
This graph consists of nodes (representing biomedical entities) and edges (representing relationships between entities).
We used a modified version of the well-known Breadth-First Search (BFS) algorithm to traverse the graph and identify relationships between two nodes.
Specifically, we modified the BFS algorithm to take into account the directionality of edges and to return the shortest path between two nodes.
We also incorporated a heuristic to further reduce the search time.
The heuristic is based on the concept of node ‘neighborhood’ and is defined mathematically as:

$$ P(u, v) = \frac{|N(u) \cap N(v)|}{|N(u) \cup N(v)|} $$ {#eq:pathsim}

where $u

Colors in the palette are also used in the Hetio logo (seen in Figure {@fig:website}) and other miscellaneous logos and iconography across the website, to establish an identifiable brand for the Hetio organization as a whole.

### Realtime open science

We used the hetnet-search algorithm to search for the connectivity of two biomedical entities.
The algorithm, which is based on the Hetionet knowledge graph, is described in detail in Equation 1.
This equation defines the connectivity score \(CS\) between two nodes \(n_1\) and \(n_2\) as the sum of the weights of the edges connecting them.

$$CS(n_1, n_2) = \sum_{e \in E} w_e$$
{#eq:connectivity_score}

The algorithm was implemented in the Python programming language and is available for download from the project's GitHub repository.
It was tested on the Bio2BEL suite of databases and on the hetnet-search benchmark dataset.
The results are discussed in the Results section.

The manuscript for this study was written using [Manubot](https://manubot.org/), which allows authors to collaboratively write manuscripts on GitHub [@doi:10.1371/journal.pcbi.1007128].
The Manubot-rendered manuscript is available at <https://greenelab.github.io/connectivity-search-manuscript/>.
We encourage readers with feedback or questions to comment publicly via [GitHub Issues](https://github.com/greenelab/connectivity-search-manuscript/issues).

### Software & data availability

The connectivity search algorithm used in this manuscript is a two-step process.
First, a set of nodes is identified by traversing the hetnet and collecting all nodes that are within a given distance of the source node.
This is accomplished using a breadth-first search (BFS) algorithm, which is defined by the following equation:

$$
BFS(G, s) \\
\text{where } G = (V, E) \\
\text{and } s \in V
$$ {#id}

Where $G$ is the graph, $V$ is the set of nodes, $E$ is the set of edges, and $s$ is the source node.
The second step of the algorithm is to identify the edges that connect the nodes identified in the first step.
This is accomplished by searching the hetnet for edges that connect the nodes within the set.
The result is a subgraph that is connected to the source node and has a maximum distance of $d$ from it.

<!-- https://github.com/topics/hetnet-connectivity-search -->
The Hetnet Connectivity Search web application is registered at [bio.tools:connectivity-search](https://bio.tools/connectivity-search).
This study primarily involves the following repositories:

- [greenelab/connectivity-search-manuscript](https://github.com/greenelab/connectivity-search-manuscript) [@https://github.com/greenelab/connectivity-search-manuscript]: Source code for this manuscript.
Best place for general comments or questions.
CC BY 4.0 License.
- [greenelab/connectivity-search-analyses](https://github.com/greenelab/connectivity-search-analyses) [@https://github.com/greenelab/connectivity-search-analyses]: The initial project repository that contains research notebooks, dataset generation code, and exploratory data analyses.
The hetmatpy package was first developed as part of this repository until its [relocation](https://github.com/hetio/hetmatpy/issues/1) in November 2018.
BSD 3-Clause License.
- [greenelab/connectivity-search-backend](https://github.com/greenelab/connectivity-search-backend) [@https://github.com/greenelab/connectivity-search-backend]: Source code for the connectivity search database and API.
BSD 3-Clause License.
- [greenelab/connectivity-search-frontend](https://github.com/greenelab/connectivity-search-frontend) [@https://github.com/greenelab/connectivity-search-frontend]: Source code for the connectivity search webapp.
BSD 3-Clause License.
- [hetio/hetmatpy](https://github.com/hetio/hetmatpy) [@https://github.com/hetio/hetmatpy]: Python package for matrix storage and operations on hetnets.
Released on [PyPI](https://pypi.org/project/hetmatpy/).
BSD 2-Clause Plus Patent License.
Registered at [bio.tools:hetmatpy](https://bio.tools/hetmatpy) and [RRID:SCR_023409](https://scicrunch.org/resolver/RRID:SCR_023409).
- [hetio/hetnetpy](https://github.com/hetio/hetnetpy) [@https://github.com/hetio/hetnetpy]: Preexisting Python package for representing hetnets.
Dependency of hetmatpy.
Released on [PyPI](https://pypi.org/project/hetnetpy/).
Dual licensed under BSD 2-Clause Plus Patent License and CC0 1.0 (public domain dedication).
- [hetio/hetionet](https://github.com/hetio/hetionet) [@https://github.com/hetio/hetionet]: Preexisting data repository for Hetionet, including the public Neo4j instance and HetMat archives.
CC0 1.0 License.
- [hetio/het.io](https://github.com/hetio/het.io) [@https://github.com/hetio/het.io]: Preexisting source code for the <https://het.io/> website.
CC BY 4.0 License.

The Hetnet Connectivity Search algorithm is based on the concept of a hetnet, a network of nodes and edges that represent biomedical entities and relationships between them.
Hetnets are represented as matrices, with each row and column representing a node, and each cell representing an edge.
We use a hetmat, a matrix representation of a hetnet that is stored as a sparse matrix, to store the hetnet.
The hetmat is constructed by applying an adjacency matrix to the hetnet, where each element $$a_{ij}$$ {#id} of the adjacency matrix represents the number of edges between nodes $$i$$ and $$j$$.
The hetmatpy Python package is used to construct and manipulate the hetmat.

The hetmech and hetionet repositories contain datasets related to this study.
Large datasets were compressed and tracked with [Git LFS](https://git-lfs.github.com/) (Large File Storage).
GitHub LFS had a max file size of 2 GB.
Datasets exceeding this size, along with other essential datasets, are available from Zenodo [@zenodo].


<!-- link reference syntax citation key aliases -->
[@hetio-dag]: doi:10.1371/journal.pcbi.1004259 [@rephetio]: doi:10.7554/eLife.26726 [@vagelos-2017]: doi:10.6084/m9.figshare.5346577 [@xswap]: https://greenelab.github.io/xswap-manuscript/ [@zenodo]: doi:10.5281/zenodo.1435833

## Competing Interests

This work was supported, in part, by Pfizer Worldwide Research, Development, and Medical.
